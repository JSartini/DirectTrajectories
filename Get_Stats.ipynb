{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get_Stats.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhB8_gvjShOD"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHZ01zuiR80Z"
      },
      "source": [
        "!rm -rf waymo-od > /dev/null\n",
        "!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
        "!cd waymo-od && git branch -a\n",
        "!cd waymo-od && git checkout remotes/origin/master\n",
        "!pip3 install --upgrade pip\n",
        "!pip3 install waymo-open-dataset-tf-2-1-0==1.2.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoYRq_t2SCL3"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzCq1omrSCp-"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdhkayGWSIPy"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse\n",
        "\n",
        "!mkdir -p data/training\n",
        "!gcsfuse --only-dir training/ waymo_open_dataset_v_1_2_0_individual_files data/training/\n",
        "\n",
        "!mkdir -p data/testing\n",
        "!gcsfuse --only-dir testing/ waymo_open_dataset_v_1_2_0_individual_files data/testing/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nr_vXerSOEh"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data_utils\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from waymo_open_dataset.utils import range_image_utils\n",
        "from waymo_open_dataset.utils import transform_utils\n",
        "from waymo_open_dataset.utils import  frame_utils\n",
        "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
        "\n",
        "from Net_Lib import *\n",
        "\n",
        "list_train = os.listdir(path='data/training')\n",
        "list_test = os.listdir(path='data/testing')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-ML44NgSkYx"
      },
      "source": [
        "# Face Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dRvxNRtSoJH"
      },
      "source": [
        "model_save_name = 'novel_checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
        "print(checkpoint['loss'])\n",
        "print(checkpoint['valid'])\n",
        "print(checkpoint['epoch'])\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(checkpoint['loss'], label=\"Training\")\n",
        "ax.plot(checkpoint['valid'], label=\"Validation\")\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Novel Loss on Waymo Subset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVIQj7YrSqm-"
      },
      "source": [
        "model_save_name = 'checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
        "print(checkpoint['loss'])\n",
        "print(checkpoint['valid'])\n",
        "print(checkpoint['epoch'])\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(checkpoint['loss'],label=\"Training\")\n",
        "ax.plot(checkpoint['valid'],label=\"Validation\")\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('YOLO Loss on Waymo Subset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eava1UoGSs9H"
      },
      "source": [
        "model_save_name = 'lstm_checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
        "print(checkpoint['loss'])\n",
        "print(checkpoint['valid'])\n",
        "print(checkpoint['epoch'])\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(checkpoint['loss'],label=\"Training\")\n",
        "ax.plot(checkpoint['valid'],label=\"Validation\")\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('LSTM Loss on Waymo Subset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5Z--EK8TB7l"
      },
      "source": [
        "# Get Average YOLO Trajectory Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsdqJ1N0tBVi"
      },
      "source": [
        "# Data extraction and preparation\n",
        "def create_trajbatch(index,train):\n",
        "  if(train):\n",
        "    loc = \"data/training/\"\n",
        "    req_list = list_train\n",
        "  else:\n",
        "    loc = \"data/testing/\"\n",
        "    req_list = list_test\n",
        "\n",
        "  train_images = []\n",
        "  train_labels = []\n",
        "  img_yes = False\n",
        "  imagenum = 0\n",
        "  for dataset in list_train[index:index+1]:\n",
        "    dataset = tf.data.TFRecordDataset(loc+dataset, compression_type='')\n",
        "    for data in dataset:\n",
        "      frame = open_dataset.Frame()\n",
        "      frame.ParseFromString(bytearray(data.numpy()))\n",
        "\n",
        "      # Get image itself\n",
        "      for index, image in enumerate(frame.images):\n",
        "        if(image.name == 1):\n",
        "          img = tf.image.decode_jpeg(image.image)\n",
        "          img = tf.image.resize(img, [640, 960])\n",
        "          train_images.append(img)\n",
        "\n",
        "      # Get label data\n",
        "      for cam_labels in frame.projected_lidar_labels:\n",
        "        if(cam_labels.name != 1):\n",
        "          continue\n",
        "        for label in cam_labels.labels:\n",
        "          train_labels.append(np.array([label.box.center_x//2, label.box.center_y//2,\n",
        "                                          label.box.width//2, label.box.length//2, label.metadata.speed_x, label.metadata.speed_y, label.metadata.accel_x,\n",
        "                                            label.metadata.accel_y, label.type, imagenum]))\n",
        "          img_yes = True\n",
        "      \n",
        "      # Write specialized \"empty image\" output\n",
        "      if(not img_yes):\n",
        "        train_labels.append(np.array([-1,-1,-1,-1,-1,-1,-1,-1,-1,imagenum]))\n",
        "      else:\n",
        "        img_yes = False\n",
        "      imagenum += 1\n",
        " \n",
        "  train_labels = torch.from_numpy(np.array(train_labels))\n",
        "  train_images = torch.from_numpy(np.array(train_images).transpose(0,3,1,2))\n",
        "  return train_labels, train_images"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXK_eXQrmCXb"
      },
      "source": [
        "def create_diffbatch(index, train):\n",
        "  if(train):\n",
        "    loc = \"data/training/\"\n",
        "    req_list = list_train\n",
        "  else:\n",
        "    loc = \"data/testing/\"\n",
        "    req_list = list_test\n",
        "\n",
        "  train_images = []\n",
        "  train_labels = []\n",
        "  imagenum = 0\n",
        "  img_yes = False\n",
        "\n",
        "  # Variables for tracking to create diffs from same frame context\n",
        "  prev_context = None\n",
        "  context = None\n",
        "  prev_img = None\n",
        "  img = None\n",
        "  \n",
        "  for dataset in req_list[index:index+1]:\n",
        "    dataset = tf.data.TFRecordDataset(loc+dataset, compression_type='')\n",
        "    for data in dataset:\n",
        "      frame = open_dataset.Frame()\n",
        "      frame.ParseFromString(bytearray(data.numpy()))\n",
        "      context = frame.context.name\n",
        "  \n",
        "      # Indicates new scene\n",
        "      if(context != prev_context or prev_context == None): \n",
        "        for index, image in enumerate(frame.images):\n",
        "          if(image.name == 1):\n",
        "            prev_img = tf.image.rgb_to_grayscale(tf.image.decode_jpeg(image.image))\n",
        "            prev_img = tf.image.resize(prev_img, [640, 960])\n",
        "        prev_context = context\n",
        "\n",
        "      # Indicates continuation\n",
        "      else: \n",
        "        for index, image in enumerate(frame.images):\n",
        "          if(image.name == 1):\n",
        "            img = tf.image.rgb_to_grayscale(tf.image.decode_jpeg(image.image))\n",
        "            img = tf.image.resize(img, [640, 960])\n",
        "            train_images.append(img-prev_img)\n",
        "\n",
        "        for cam_labels in frame.projected_lidar_labels:\n",
        "          if(cam_labels.name != 1):\n",
        "            continue\n",
        "          for label in cam_labels.labels:\n",
        "            train_labels.append(np.array([label.box.center_x//2, label.box.center_y//2,\n",
        "                                          label.box.width//2, label.box.length//2, label.metadata.speed_x, \n",
        "                                            label.metadata.speed_y, label.metadata.accel_x,\n",
        "                                            label.metadata.accel_y, label.type, imagenum]))\n",
        "            img_yes = True\n",
        "\n",
        "        if(not img_yes):\n",
        "          train_labels.append(np.array([-1,-1,-1,-1,-1,-1,-1,-1,-1,imagenum]))\n",
        "        else:\n",
        "          img_yes = False\n",
        "        imagenum += 1\n",
        "\n",
        "  train_labels = torch.from_numpy(np.array(train_labels))\n",
        "  train_images = torch.from_numpy(np.array(train_images).transpose(0,3,1,2))\n",
        "  return train_labels, train_images"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffRIirw-kIXP"
      },
      "source": [
        "# Data extraction and preparation\n",
        "def create_LSTMbatch(index,train):\n",
        "  if(train):\n",
        "    loc = \"data/training/\"\n",
        "    req_list = list_train\n",
        "  else:\n",
        "    loc = \"data/testing/\"\n",
        "    req_list = list_test\n",
        "\n",
        "  train_images = []\n",
        "  train_labels = []\n",
        "  img_yes = False\n",
        "  imagenum = 0\n",
        "  for dataset in list_train[index:index+1]:\n",
        "    dataset = tf.data.TFRecordDataset(loc+dataset, compression_type='')\n",
        "    for data in dataset:\n",
        "      frame = open_dataset.Frame()\n",
        "      frame.ParseFromString(bytearray(data.numpy()))\n",
        "\n",
        "      # Get image itself\n",
        "      for index, image in enumerate(frame.images):\n",
        "        if(image.name == 1):\n",
        "          img = tf.image.decode_jpeg(image.image)\n",
        "          img = tf.image.resize(img, [640, 960])\n",
        "          train_images.append(img)\n",
        "\n",
        "      # Get label data\n",
        "      for cam_labels in frame.projected_lidar_labels:\n",
        "        if(cam_labels.name != 1):\n",
        "          continue\n",
        "        for label in cam_labels.labels:\n",
        "          train_labels.append(np.array([label.metadata.speed_x, label.metadata.speed_y, label.metadata.accel_x,\n",
        "                                            label.metadata.accel_y, imagenum]))\n",
        "          img_yes = True\n",
        "      \n",
        "      # Write specialized \"empty image\" output\n",
        "      if(not img_yes):\n",
        "        train_labels.append(np.array([-1,-1,-1,-1,imagenum]))\n",
        "      else:\n",
        "        img_yes = False\n",
        "      imagenum += 1\n",
        " \n",
        "  train_labels = torch.from_numpy(np.array(train_labels))\n",
        "  train_images = torch.from_numpy(np.array(train_images).transpose(0,3,1,2))\n",
        "  return train_labels, train_images"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMB3bPSWTOyf"
      },
      "source": [
        "anchors = torch.load(\"anch.pt\")\n",
        "num_anchors = anchors.shape[0]\n",
        "res = 32\n",
        "a_cuda=True\n",
        "H = 1280//(2*res)                   # height of the grid over images\n",
        "W = 1920//(2*res)                   # width of the grid over images\n",
        "batchsize=16\n",
        "\n",
        "network_spec = parse_cfg(\"yolo.cfg\")\n",
        "module_list = create_network(network_spec, 3)\n",
        "yolo = Model(module_list).float()\n",
        "model_save_name = 'checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path)\n",
        "yolo.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "network_spec = parse_cfg(\"novel.cfg\")\n",
        "module_list = create_network(network_spec, 1)\n",
        "novel = Model(module_list).float()\n",
        "model_save_name = 'novel_checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path)\n",
        "novel.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "model_save_name = 'lstm_checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "recurrent = LSTM_module(W*H*50, 360, 2, W*H*5)\n",
        "checkpoint = torch.load(path)\n",
        "recurrent.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "checkpoint = None\n",
        "if(a_cuda):\n",
        "  anchors = anchors.cuda()\n",
        "  yolo = yolo.cuda()\n",
        "  novel = novel.cuda()\n",
        "  recurrent = recurrent.cuda()\n",
        "\n",
        "overall_yolo = []\n",
        "overall_novel = []\n",
        "overall_lstm = []\n",
        "for i in [0,1,2,3,4,5,6,7,8,9]:\n",
        "  print(\"i:\"+str(i))\n",
        "  ylabels, yimages = create_trajbatch(i, True)\n",
        "  nlabels, nimages = create_diffbatch(i, True)\n",
        "  llabels, _ = create_LSTMbatch(i, True)\n",
        "  ntrain = yimages.shape[0]\n",
        "  num_its = ntrain//batchsize\n",
        "  yolo_errors = np.zeros(num_its)\n",
        "  novel_errors = np.zeros(num_its)\n",
        "  lstm_errors = np.zeros(num_its)\n",
        "\n",
        "  for t in range(ntrain // batchsize):\n",
        "    print(\"t:\"+str(t))\n",
        "    batchindices = np.arange(t*batchsize, (t+1)*batchsize)\n",
        "    this_batch = Variable(yimages[batchindices,...].float())\n",
        "    diff_batch = Variable(nimages[batchindices,...].float())\n",
        "    if(a_cuda):\n",
        "        this_batch = this_batch.cuda()\n",
        "        diff_batch = diff_batch.cuda()\n",
        "\n",
        "    with(torch.no_grad()):\n",
        "      yout = yolo(this_batch)\n",
        "      nout = novel(diff_batch)\n",
        "\n",
        "    cyout = yout.detach().clone()\n",
        "    lstm_input = shape_for_LSTM(cyout, a_cuda)\n",
        "    lstm_output = recurrent(lstm_input)\n",
        "    lstm_output = lstm_output.view(batchsize-1, 5, H, W)\n",
        "\n",
        "\n",
        "    yout = nms_thresh(yout, 0.75, anchors, a_cuda, res)\n",
        "    nout = nms_thresh(nout, 0.75, anchors, a_cuda, res)\n",
        "\n",
        "    adj_out = match_boxes(yout, anchors, 25, (1280//2,1920//2), a_cuda)\n",
        "    if(a_cuda):\n",
        "      adj_out = adj_out.cuda()\n",
        "\n",
        "    ylabel_indices = (ylabels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "    nlabel_indices = (nlabels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "    llabel_indices = (llabels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "    true_out = ylabels[ylabel_indices,:]\n",
        "    diff_out = nlabels[nlabel_indices,:]\n",
        "    lstm_out = llabels[llabel_indices,:]\n",
        "    if(a_cuda):\n",
        "      true_out = true_out.cuda()\n",
        "      diff_out = diff_out.cuda()\n",
        "      lstm_out = lstm_out.cuda()\n",
        "    \n",
        "\n",
        "    _, yolo_traj, _ = novel_train(true_out, (H,W), anchors, res, a_cuda, batchsize)\n",
        "    _, novel_traj, _ = novel_train(diff_out, (H,W), anchors, res, a_cuda, batchsize)\n",
        "    lstm_traj, _ = transform_LSTM_train(lstm_out, res, (H,W), a_cuda)\n",
        "\n",
        "    yolo_errors[t] = F.mse_loss(adj_out, yolo_traj[1:,:,:2,:,:]).item()\n",
        "    novel_errors[t] = F.mse_loss(nout.view(batchsize, num_anchors, 9, H, W)[:,:,5:7, :,:], novel_traj[:,:,:2,:,:])\n",
        "    lstm_errors[t] = F.mse_loss(lstm_output[:,:2,:,:], lstm_traj[:,:2,:,:])\n",
        "\n",
        "    # remove from memory\n",
        "    this_batch = None\n",
        "    true_out = None\n",
        "    yout = None\n",
        "    nout = None\n",
        "    adj_out = None\n",
        "    lstm_traj = None\n",
        "    novel_traj = None\n",
        "    gc.collect()\n",
        "    if(a_cuda):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  overall_yolo.append(np.mean(yolo_errors))\n",
        "  overall_novel.append(np.mean(novel_errors))\n",
        "  overall_lstm.append(np.mean(lstm_errors))\n",
        "\n",
        "print(np.mean(np.array(overall_yolo)))\n",
        "print(np.mean(np.array(overall_novel)))\n",
        "print(np.mean(np.array(overall_lstm)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}