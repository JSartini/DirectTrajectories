{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_TrainV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66lpWaVO76Dt"
      },
      "source": [
        "# Data setup and Environment Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI9efppQlzj4"
      },
      "source": [
        "!rm -rf waymo-od > /dev/null\n",
        "!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
        "!cd waymo-od && git branch -a\n",
        "!cd waymo-od && git checkout remotes/origin/master\n",
        "!pip3 install --upgrade pip\n",
        "!pip3 install waymo-open-dataset-tf-2-1-0==1.2.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_WS2Bcb8G9u"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJyMso56wSaE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHhn-1jc8HR5"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse\n",
        "\n",
        "!mkdir -p data/training\n",
        "!gcsfuse --only-dir training/ waymo_open_dataset_v_1_2_0_individual_files data/training/\n",
        "\n",
        "!mkdir -p data/testing\n",
        "!gcsfuse --only-dir testing/ waymo_open_dataset_v_1_2_0_individual_files data/testing/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeNzfDl38NWF"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data_utils\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from waymo_open_dataset.utils import range_image_utils\n",
        "from waymo_open_dataset.utils import transform_utils\n",
        "from waymo_open_dataset.utils import  frame_utils\n",
        "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
        "\n",
        "from Net_Lib import parse_cfg, box_iou, create_network, Model, YOLO_loss, Novel_loss, LSTM_loss\n",
        "\n",
        "list_train = os.listdir(path='data/training')\n",
        "list_test = os.listdir(path='data/testing')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RpXWLkPTXP3"
      },
      "source": [
        "# Calculation of Necessary Components for all Models (Anchor boxes and Training Indices)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIGv8BUV_d-i"
      },
      "source": [
        "# Choose random data repos from the bank to use in clustering\n",
        "indices = np.random.choice(len(list_train), 20, replace=False)\n",
        "for i in range(len(indices)):\n",
        "  if(i == 0):\n",
        "    train_labels, _ = create_yolobatch(indices[i], True)\n",
        "  else:\n",
        "    new_labels, _ = create_yolobatch(indices[i], True)\n",
        "    train_labels = torch.cat((train_labels, new_labels), 0)\n",
        "\n",
        "# Find anchor box sizes through k-means clustering\n",
        "cluster_labels = train_labels[(train_labels[:,-2] != -1),:]\n",
        "num_examples = cluster_labels.shape[0]\n",
        "num_clusters = 5\n",
        "# train\n",
        "num_iterations = 5000\n",
        "min = torch.min(cluster_labels[:,2:4], 0)[0]\n",
        "max = torch.max(cluster_labels[:,2:4], 0)[0]\n",
        "widths = torch.from_numpy(np.random.uniform(min[0].item(),max[0].item(),(num_clusters,1)))\n",
        "heights = torch.from_numpy(np.random.uniform(min[1].item(),max[1].item(),(num_clusters,1)))\n",
        "xy = torch.zeros((num_clusters, 2))\n",
        "centers = torch.cat((xy, widths, heights), 1)\n",
        "assignments = torch.zeros(num_examples)\n",
        "for _ in range(num_iterations):\n",
        "  test = torch.cat((torch.zeros((num_examples, 2)), cluster_labels[:,2:4]), 1)\n",
        "  distances = box_iou(centers, test)\n",
        "  _, assignments = torch.max(distances, 0)\n",
        "\n",
        "  for k in range(num_clusters):\n",
        "    if(torch.sum(assignments==k).item() > 0):\n",
        "      centers[k,2:] = torch.mean(cluster_labels[assignments==k,2:4],axis=0)\n",
        "    else:\n",
        "      centers[k, 2] = torch.from_numpy(np.random.uniform(min[0].item(), max[0].item(), (1,1)))\n",
        "      centers[k, 3] = torch.from_numpy(np.random.uniform(min[1].item(), max[1].item(), (1,1)))\n",
        "\n",
        "# Just return the desired portion\n",
        "anchors = centers[:,2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drUhfgRwMB_9"
      },
      "source": [
        "train_idxs = np.random.choice(len(list_train)-25,100)\n",
        "validation = np.arange(len(list_train))[-25:]\n",
        "torch.save(train_idxs, \"train_idx.pt\")\n",
        "torch.save(validation, \"valid_idx.pt\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUzVMWSKhte6"
      },
      "source": [
        "# Yolo Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKoARmY_bnDh"
      },
      "source": [
        "## Batch-maker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys-i4rNu8Pzk"
      },
      "source": [
        "# Data extraction and preparation\n",
        "def create_yolobatch(index,train):\n",
        "  if(train):\n",
        "    loc = \"data/training/\"\n",
        "    req_list = list_train\n",
        "  else:\n",
        "    loc = \"data/testing/\"\n",
        "    req_list = list_test\n",
        "  train_images = []\n",
        "  train_labels = []\n",
        "  img_yes = False\n",
        "  imagenum = 0\n",
        "  for dataset in req_list[index:index+1]:\n",
        "    dataset = tf.data.TFRecordDataset(loc+dataset, compression_type='')\n",
        "    for data in dataset:\n",
        "      frame = open_dataset.Frame()\n",
        "      frame.ParseFromString(bytearray(data.numpy()))\n",
        "\n",
        "      # Get image itself\n",
        "      for index, image in enumerate(frame.images):\n",
        "        if(image.name == 1):\n",
        "          img = tf.image.decode_jpeg(image.image)\n",
        "          img = tf.image.resize(img, [640, 960])\n",
        "          train_images.append(img)\n",
        "\n",
        "      # Get label data\n",
        "      for cam_labels in frame.projected_lidar_labels:\n",
        "        if(cam_labels.name != 1):\n",
        "          continue\n",
        "        for label in cam_labels.labels:\n",
        "          train_labels.append(np.array([label.box.center_x//2, label.box.center_y//2,\n",
        "                                            label.box.width//2, label.box.length//2, \n",
        "                                            label.type, imagenum]))\n",
        "          img_yes = True\n",
        "      \n",
        "      # Write specialized \"empty image\" output\n",
        "      if(not img_yes):\n",
        "        train_labels.append(np.array([-1,-1,-1,-1,-1,imagenum]))\n",
        "      else:\n",
        "        img_yes = False\n",
        "      imagenum += 1\n",
        "  \n",
        "  train_labels = torch.from_numpy(np.array(train_labels))\n",
        "  train_images = torch.from_numpy(np.array(train_images).transpose(0,3,1,2))\n",
        "  return train_labels, train_images"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80WwYsmfGGQ5"
      },
      "source": [
        "## Perform Basic YOLO Training using Library of Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JSksZ6T9x0F"
      },
      "source": [
        "n_tot_train = len(list_train)  # number of overall training examples\n",
        "\n",
        "nepoch_readbatch = 25          # number of epochs through training set\n",
        "batchsize = 16                 # minibatch size\n",
        "a_cuda = True                  # whether or not to enable cuda gpu acceleration\n",
        "\n",
        "res = 32                       # resolution of image breakdown\n",
        "H = 1280//(2*res)                   # height of the grid over images\n",
        "W = 1920//(2*res)                   # width of the grid over images\n",
        "\n",
        "network_spec = parse_cfg(\"yolo.cfg\")\n",
        "module_list = create_network(network_spec, 3)\n",
        "yolo = Model(module_list).float()\n",
        "if(a_cuda):\n",
        "  yolo.cuda()\n",
        "anchors = torch.load(\"anch.pt\")\n",
        "if(a_cuda):\n",
        "  anchors.cuda()\n",
        "yloss = YOLO_loss(5, 1, 1, 1, res, anchors, (H, W), a_cuda, batchsize)\n",
        "losses = []\n",
        "\n",
        "# use ADAM optimizer\n",
        "optimizer = optim.Adam(yolo.parameters(), lr=1E-5)\n",
        "\n",
        "for i in [0]:\n",
        "  labels, images = create_yolobatch(i, True)\n",
        "  ntrain = images.shape[0]\n",
        "  \n",
        "  # for loop to get from different batches of read-in images\n",
        "  for iepoch in range(nepoch_readbatch):\n",
        "    num_its = int(ntrain/batchsize)\n",
        "    ep_loss = np.zeros(num_its)\n",
        "    print(iepoch) \n",
        "    for t in range(int(ntrain / batchsize)):\n",
        "        batchindices = np.random.choice(ntrain, batchsize, replace=False)\n",
        "\n",
        "        # before the forward pass, clean the gradient buffers of all parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        this_batch = Variable(images[batchindices,...].float())\n",
        "        if(a_cuda):\n",
        "          this_batch = this_batch.cuda()\n",
        "        out = yolo(this_batch)\n",
        "\n",
        "        # MSE loss\n",
        "        label_indices = (labels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "        true_out = labels[label_indices,:]\n",
        "        if(a_cuda):\n",
        "          true_out = true_out.cuda()\n",
        "        \n",
        "        loss = yloss(out, true_out)\n",
        "        ep_loss[t] = loss.item()\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update parameters using SGD\n",
        "        optimizer.step()\n",
        "\n",
        "        # remove from memory\n",
        "        this_batch = None\n",
        "        true_out = None\n",
        "        out = None\n",
        "        gc.collect()\n",
        "        if(a_cuda):\n",
        "          torch.cuda.empty_cache()\n",
        "        \n",
        "    losses.append(np.mean(ep_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_QvfyOrayKS"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(losses)\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('YOLOV2 Loss on Waymo Subset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBdnSej5VNoX"
      },
      "source": [
        "## Perform full-scale YOLO Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQPHp_YLv44K"
      },
      "source": [
        "model_save_name = 'checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path)\n",
        "print(checkpoint['loss'])\n",
        "print(checkpoint['valid'])\n",
        "print(checkpoint['epoch'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0cwQXcOVVMd"
      },
      "source": [
        "model_save_name = 'checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "resume = True\n",
        "\n",
        "tot_train = torch.load(\"train_idx.pt\")  # number of overall training examples\n",
        "tot_valid = torch.load(\"valid_idx.pt\")\n",
        "n_tot_train = len(tot_train)\n",
        "\n",
        "nepoch_dataset = 20            # number of epochs through training set\n",
        "batchsize = 16                 # minibatch size\n",
        "a_cuda = True                  # whether or not to enable cuda gpu acceleration\n",
        "\n",
        "res = 32                       # resolution of image breakdown\n",
        "H = 1280//(2*res)                   # height of the grid over images\n",
        "W = 1920//(2*res)                   # width of the grid over images\n",
        "\n",
        "network_spec = parse_cfg(\"yolo.cfg\")\n",
        "module_list = create_network(network_spec, 3)\n",
        "yolo = Model(module_list).float()\n",
        "if(a_cuda):\n",
        "  yolo.cuda()\n",
        "anchors = torch.load(\"anch.pt\")\n",
        "\n",
        "yloss = YOLO_loss(5, 1, 1, 1, res, anchors, (H, W), a_cuda, batchsize)\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "epoch = 0\n",
        "\n",
        "# use ADAM optimizer\n",
        "optimizer = optim.Adam(yolo.parameters(), lr=1E-5, weight_decay=0.0005)\n",
        "\n",
        "# Code for resume\n",
        "if(resume):\n",
        "  checkpoint = torch.load(path)\n",
        "  yolo.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']+1\n",
        "  train_losses = checkpoint['loss']\n",
        "  valid_losses = checkpoint['valid']\n",
        "\n",
        "num_images = 200*n_tot_train\n",
        "num_steps = num_images//batchsize\n",
        "\n",
        "for iepoch in range(epoch, nepoch_dataset):\n",
        "  ep_loss = np.zeros(num_steps)\n",
        "  print(\"Epoch:\" +str(iepoch))\n",
        "  # for loop to train through different batches of read-in images\n",
        "  for j in range(num_steps):\n",
        "    print(str(j) + \"/\" + str(num_steps))\n",
        "    index = int(np.random.choice(tot_train,1)[0])\n",
        "    labels, images = create_yolobatch(index, True)\n",
        "    ntrain = images.shape[0]\n",
        "    batchindices = np.random.choice(ntrain, batchsize, replace=False)\n",
        "\n",
        "    # before the forward pass, clean the gradient buffers of all parameters\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    this_batch = Variable(images[batchindices,...].float())\n",
        "    if(a_cuda):\n",
        "      this_batch = this_batch.cuda()\n",
        "    out = yolo(this_batch)\n",
        "\n",
        "    # MSE loss\n",
        "    label_indices = (labels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "    true_out = labels[label_indices,:]\n",
        "    if(a_cuda):\n",
        "      true_out = true_out.cuda()\n",
        "\n",
        "    loss = yloss(out, true_out)\n",
        "    ep_loss[j] = loss.item()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # update parameters using SGD\n",
        "    optimizer.step()\n",
        "\n",
        "    # remove from memory\n",
        "    this_batch = None\n",
        "    true_out = None\n",
        "    out = None\n",
        "    gc.collect()\n",
        "    if(a_cuda):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  # Record training loss\n",
        "  train_losses.append(np.mean(ep_loss))\n",
        "\n",
        "  # Calculate and record validation loss using test set\n",
        "  valid = np.zeros(len(tot_valid))\n",
        "  for i in range(len(tot_valid)):\n",
        "    index = int(tot_valid[i])\n",
        "    labels, images = create_yolobatch(index, True)\n",
        "    ntest = images.shape[0]\n",
        "    batchindices = np.random.choice(ntest, batchsize, replace=False)\n",
        "    this_batch = Variable(images[batchindices,...].float())\n",
        "    if(a_cuda):\n",
        "      this_batch = this_batch.cuda()\n",
        "    out = yolo(this_batch)\n",
        "    label_indices = (labels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "    true_out = labels[label_indices,:]\n",
        "    if(a_cuda):\n",
        "      true_out = true_out.cuda()\n",
        "    valid[i] = yloss(out, true_out)\n",
        "\n",
        "    this_batch = None\n",
        "    true_out = None\n",
        "    out = None\n",
        "    gc.collect()\n",
        "    if(a_cuda):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  valid_losses.append(np.mean(valid))\n",
        "  torch.save({\n",
        "            'epoch': iepoch,\n",
        "            'model_state_dict': yolo.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': train_losses,\n",
        "            'valid': valid_losses\n",
        "            }, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3gu4Znmb1VB"
      },
      "source": [
        "# Novel Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWg4oLOKgTTo"
      },
      "source": [
        "## Difference Batch-Maker\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtlcnjOqgSb4"
      },
      "source": [
        "def create_diffbatch(index, train):\n",
        "  if(train):\n",
        "    loc = \"data/training/\"\n",
        "    req_list = list_train\n",
        "  else:\n",
        "    loc = \"data/testing/\"\n",
        "    req_list = list_test\n",
        "\n",
        "  train_images = []\n",
        "  train_labels = []\n",
        "  imagenum = 0\n",
        "  img_yes = False\n",
        "\n",
        "  # Variables for tracking to create diffs from same frame context\n",
        "  prev_context = None\n",
        "  context = None\n",
        "  prev_img = None\n",
        "  img = None\n",
        "  \n",
        "  for dataset in req_list[index:index+1]:\n",
        "    dataset = tf.data.TFRecordDataset(loc+dataset, compression_type='')\n",
        "    for data in dataset:\n",
        "      frame = open_dataset.Frame()\n",
        "      frame.ParseFromString(bytearray(data.numpy()))\n",
        "      context = frame.context.name\n",
        "  \n",
        "      # Indicates new scene\n",
        "      if(context != prev_context or prev_context == None): \n",
        "        for index, image in enumerate(frame.images):\n",
        "          if(image.name == 1):\n",
        "            prev_img = tf.image.rgb_to_grayscale(tf.image.decode_jpeg(image.image))\n",
        "            prev_img = tf.image.resize(prev_img, [640, 960])\n",
        "        prev_context = context\n",
        "\n",
        "      # Indicates continuation\n",
        "      else: \n",
        "        for index, image in enumerate(frame.images):\n",
        "          if(image.name == 1):\n",
        "            img = tf.image.rgb_to_grayscale(tf.image.decode_jpeg(image.image))\n",
        "            img = tf.image.resize(img, [640, 960])\n",
        "            train_images.append(img-prev_img)\n",
        "\n",
        "        for cam_labels in frame.projected_lidar_labels:\n",
        "          if(cam_labels.name != 1):\n",
        "            continue\n",
        "          for label in cam_labels.labels:\n",
        "            train_labels.append(np.array([label.box.center_x//2, label.box.center_y//2,\n",
        "                                          label.box.width//2, label.box.length//2, label.metadata.speed_x, \n",
        "                                            label.metadata.speed_y, label.metadata.accel_x,\n",
        "                                            label.metadata.accel_y, label.type, imagenum]))\n",
        "            img_yes = True\n",
        "\n",
        "        if(not img_yes):\n",
        "          train_labels.append(np.array([-1,-1,-1,-1,-1,-1,-1,-1,-1,imagenum]))\n",
        "        else:\n",
        "          img_yes = False\n",
        "        imagenum += 1\n",
        "\n",
        "  train_labels = torch.from_numpy(np.array(train_labels))\n",
        "  train_images = torch.from_numpy(np.array(train_images).transpose(0,3,1,2))\n",
        "  return train_labels, train_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UfWN7mGaE4l"
      },
      "source": [
        "## Train Novel Network Using Library of Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoE-jGWOaAsT"
      },
      "source": [
        "n_tot_train = len(list_train)  # number of overall training examples\n",
        "\n",
        "nepoch_readbatch = 25          # number of epochs through training set\n",
        "batchsize = 16                 # minibatch size\n",
        "a_cuda = True                  # whether or not to enable cuda gpu acceleration\n",
        "\n",
        "res = 32                       # resolution of image breakdown\n",
        "H = 1280//(2*res)                   # height of the grid over images\n",
        "W = 1920//(2*res)                   # width of the grid over images\n",
        "\n",
        "network_spec = parse_cfg(\"novel.cfg\")\n",
        "module_list = create_network(network_spec, 1)\n",
        "novel = Model(module_list).float()\n",
        "if(a_cuda):\n",
        "  novel.cuda()\n",
        "anchors = torch.load(\"anch.pt\")\n",
        "\n",
        "nloss = Novel_loss(anchors, 3, 5, 5, 1, 1, res, (H, W), a_cuda, batchsize)\n",
        "losses = []\n",
        "\n",
        "# use ADAM optimizer\n",
        "optimizer = optim.Adam(novel.parameters(), lr=1E-6, weight_decay=0.0005)\n",
        "#optimizer = optim.SGD(novel.parameters(), lr=0.0001)\n",
        "\n",
        "for i in [2]:\n",
        "  labels, images = create_diffbatch(i, True)\n",
        "  ntrain = images.shape[0]\n",
        "  # for loop to get from different batches of read-in images\n",
        "  for iepoch in range(nepoch_readbatch):\n",
        "    num_its = int(ntrain/batchsize)\n",
        "    ep_loss = np.zeros(num_its) \n",
        "    print(iepoch)\n",
        "    for t in range(num_its):\n",
        "        batchindices = np.random.choice(ntrain, batchsize, replace=False)\n",
        "\n",
        "        # before the forward pass, clean the gradient buffers of all parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        this_batch = Variable(images[batchindices,...].float())\n",
        "        if(a_cuda):\n",
        "          this_batch = this_batch.cuda()\n",
        "        out = novel(this_batch)\n",
        "\n",
        "        # MSE loss\n",
        "        label_indices = (labels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "        true_out = labels[label_indices,:]\n",
        "        if(a_cuda):\n",
        "          true_out = true_out.cuda()\n",
        "        \n",
        "        loss = nloss(out, true_out)\n",
        "        ep_loss[t] = loss.item()\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update parameters using SGD\n",
        "        optimizer.step()\n",
        "\n",
        "        # remove from memory\n",
        "        this_batch = None\n",
        "        true_out = None\n",
        "        out = None\n",
        "        gc.collect()\n",
        "        if(a_cuda):\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "    losses.append(np.mean(ep_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y529vfk3230v"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(losses)\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Novel Loss on Waymo Subset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw13rI76sag3"
      },
      "source": [
        "## Perform full-scale Novel Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evl4Un5usfWk"
      },
      "source": [
        "model_save_name = 'novel_checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path)\n",
        "print(checkpoint['loss'])\n",
        "print(checkpoint['valid'])\n",
        "print(checkpoint['epoch'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVimkgSHsiFC"
      },
      "source": [
        "model_save_name = 'novel_checkpoint.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "resume = True\n",
        "\n",
        "tot_train = torch.load(\"train_idx.pt\")  # number of overall training examples\n",
        "tot_valid = torch.load(\"valid_idx.pt\")\n",
        "n_tot_train = len(tot_train)\n",
        "\n",
        "nepoch_dataset = 20            # number of epochs through training set\n",
        "batchsize = 16                 # minibatch size\n",
        "a_cuda = True                  # whether or not to enable cuda gpu acceleration\n",
        "\n",
        "res = 32                       # resolution of image breakdown\n",
        "H = 1280//(2*res)                   # height of the grid over images\n",
        "W = 1920//(2*res)                   # width of the grid over images\n",
        "epoch = 0\n",
        "\n",
        "network_spec = parse_cfg(\"novel.cfg\")\n",
        "module_list = create_network(network_spec, 1)\n",
        "novel = Model(module_list).float()\n",
        "if(a_cuda):\n",
        "  novel = novel.cuda()\n",
        "anchors = torch.load(\"anch.pt\")\n",
        "\n",
        "nloss = Novel_loss(anchors, 3, 5, 5, 1, 1, res, (H, W), a_cuda, batchsize)\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# use ADAM optimizer\n",
        "optimizer = optim.Adam(novel.parameters(), lr=1E-6, weight_decay=0.0005)\n",
        "\n",
        "# Code for resume\n",
        "if(resume):\n",
        "  checkpoint = torch.load(path)\n",
        "  novel.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']+1\n",
        "  train_losses = checkpoint['loss']\n",
        "  valid_losses = checkpoint['valid']\n",
        "\n",
        "num_images = 200*n_tot_train\n",
        "num_steps = num_images//batchsize\n",
        "\n",
        "for iepoch in range(epoch, nepoch_dataset):\n",
        "  ep_loss = np.zeros(num_steps)\n",
        "  print(\"Epoch:\" +str(iepoch))\n",
        "  # for loop to train through different batches of read-in images\n",
        "  for j in range(num_steps):\n",
        "    print(str(j) + \"/\" + str(num_steps))\n",
        "    index = int(np.random.choice(tot_train,1)[0])\n",
        "    labels, images = create_diffbatch(index, True)\n",
        "    ntrain = images.shape[0]\n",
        "    batchindices = np.random.choice(ntrain, batchsize, replace=False)\n",
        "\n",
        "    # before the forward pass, clean the gradient buffers of all parameters\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    this_batch = Variable(images[batchindices,...].float())\n",
        "    if(a_cuda):\n",
        "      this_batch = this_batch.cuda()\n",
        "    out = novel(this_batch)\n",
        "\n",
        "    # MSE loss\n",
        "    label_indices = (labels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "    true_out = labels[label_indices,:]\n",
        "    if(a_cuda):\n",
        "      true_out = true_out.cuda()\n",
        "\n",
        "    loss = nloss(out, true_out)\n",
        "    ep_loss[j] = loss.item()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # update parameters using SGD\n",
        "    optimizer.step()\n",
        "\n",
        "    # remove from memory\n",
        "    this_batch = None\n",
        "    true_out = None\n",
        "    out = None\n",
        "    gc.collect()\n",
        "    if(a_cuda):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  # Record training loss\n",
        "  train_losses.append(np.mean(ep_loss))\n",
        "\n",
        "  # Calculate and record validation loss using test set\n",
        "  valid = np.zeros(len(tot_valid))\n",
        "  for i in range(len(tot_valid)):\n",
        "    index = int(tot_valid[i])\n",
        "    labels, images = create_diffbatch(index, True)\n",
        "    ntest = images.shape[0]\n",
        "    batchindices = np.random.choice(ntest, batchsize, replace=False)\n",
        "    this_batch = Variable(images[batchindices,...].float())\n",
        "    if(a_cuda):\n",
        "      this_batch = this_batch.cuda()\n",
        "    out = novel(this_batch)\n",
        "    label_indices = (labels[:, -1][..., None] == torch.tensor(batchindices)).any(-1).nonzero().squeeze()\n",
        "    true_out = labels[label_indices,:]\n",
        "    if(a_cuda):\n",
        "      true_out = true_out.cuda()\n",
        "    valid[i] = nloss(out, true_out)\n",
        "\n",
        "    this_batch = None\n",
        "    true_out = None\n",
        "    out = None\n",
        "    gc.collect()\n",
        "    if(a_cuda):\n",
        "      torch.cuda.empty_cache()\n",
        "  valid_losses.append(np.mean(valid))\n",
        "\n",
        "  torch.save({\n",
        "            'epoch': iepoch,\n",
        "            'model_state_dict': novel.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': train_losses,\n",
        "            'valid': valid_losses\n",
        "            }, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDXsMzMOLgDW"
      },
      "source": [
        "# Data extraction and preparation\n",
        "def create_LSTMbatch(index,train):\n",
        "  if(train):\n",
        "    loc = \"data/training/\"\n",
        "    req_list = list_train\n",
        "  else:\n",
        "    loc = \"data/testing/\"\n",
        "    req_list = list_test\n",
        "\n",
        "  train_images = []\n",
        "  train_labels = []\n",
        "  img_yes = False\n",
        "  imagenum = 0\n",
        "  for dataset in list_train[index:index+1]:\n",
        "    dataset = tf.data.TFRecordDataset(loc+dataset, compression_type='')\n",
        "    for data in dataset:\n",
        "      frame = open_dataset.Frame()\n",
        "      frame.ParseFromString(bytearray(data.numpy()))\n",
        "\n",
        "      # Get image itself\n",
        "      for index, image in enumerate(frame.images):\n",
        "        if(image.name == 1):\n",
        "          img = tf.image.decode_jpeg(image.image)\n",
        "          img = tf.image.resize(img, [640, 960])\n",
        "          train_images.append(img)\n",
        "\n",
        "      # Get label data\n",
        "      for cam_labels in frame.projected_lidar_labels:\n",
        "        if(cam_labels.name != 1):\n",
        "          continue\n",
        "        for label in cam_labels.labels:\n",
        "          train_labels.append(np.array([label.box.center_x//2, label.box.center_y//2,\n",
        "                                          label.box.width//2, label.box.length//2, label.metadata.speed_x, \n",
        "                                            label.metadata.speed_y, label.metadata.accel_x,\n",
        "                                            label.metadata.accel_y, label.type, imagenum]))\n",
        "          img_yes = True\n",
        "      \n",
        "      # Write specialized \"empty image\" output\n",
        "      if(not img_yes):\n",
        "        train_labels.append(np.array([-1,-1,-1,-1,-1,-1,-1,-1,-1,imagenum]))\n",
        "      else:\n",
        "        img_yes = False\n",
        "      imagenum += 1\n",
        " \n",
        "  train_labels = torch.from_numpy(np.array(train_labels))\n",
        "  train_images = torch.from_numpy(np.array(train_images).transpose(0,3,1,2))\n",
        "  return train_labels, train_images"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}